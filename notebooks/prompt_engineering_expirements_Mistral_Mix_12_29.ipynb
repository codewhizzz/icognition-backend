{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 2: Prompt Engineering Expirements to Extract Information\n",
    "\n",
    "This notebook documents expirements with Llama 2 prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, os, json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use Llama 2 70B on HuggingFace requires an authentication token and HuggingFace Pro account that cost $9 a month.  \n",
    "# To learn more see \n",
    "# - https://huggingface.co/meta-llama/Llama-2-70b-chat-hf?inference_api=true\n",
    "# - https://huggingface.co/pricing\n",
    "\n",
    "# Loading authentication token from .env file\n",
    "load_dotenv('../.env')\n",
    "together_token = os.getenv(\"TOGETHER_TOEKN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize methods and class that will be used in the expirements below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object to represent an answer from Llama\n",
    "class Answer:\n",
    "    def __init__(self, answer, elapse):\n",
    "        self.answer = answer\n",
    "        self.elapse = elapse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"  #  \"togethercomputer/llama-2-13b-chat\"\n",
    "\n",
    "def together_generate(prompt, temperature = 0.2, top_p = 0.8, top_k = 70) -> str:\n",
    "\n",
    "    URL = \"https://api.together.xyz/inference\"\n",
    "    \n",
    "    #  \"stop\": \".\",\n",
    "    payload = {\n",
    "        \"model\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "        \"repetition_penalty\": 1,\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {together_token}\",\n",
    "        \"User-Agent\": \"Acme Benchmark\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, json=payload, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        print(response.text)\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function that run generate and return an Answer\n",
    "def run_prompt(prompt: str, temperature = 0.2, top_p = 0.8, top_k = 70) -> Answer:\n",
    "    start_time = time.time()\n",
    "    res = together_generate(prompt)\n",
    "    answer = res['output']['choices'][0]['text']\n",
    "    end_time = time.time()\n",
    "    elapse = round(end_time - start_time)\n",
    "    return Answer(answer, elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display answer object in HTML\n",
    "def display_answer(answer: Answer, header = ''):\n",
    "    answer_html_template = \"\"\"<h3>{HEADER} Answer - Time to Generate: {ELAPSE} seconds</h3>\n",
    "    <textarea cols='100' rows={NUM_ROWS}>{ANSWER}</textarea>\"\"\"\n",
    "    \n",
    "    number_rows = (len(answer.answer.split(' ')) / 10)\n",
    "    \n",
    "    html = answer_html_template.format(ANSWER=answer.answer, ELAPSE=answer.elapse, HEADER=header, NUM_ROWS=number_rows)\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Expirements Focus\n",
    "The expirements will be focused on extracting information from a blogpost from Addresson Horoviz about mobile games soft launch. Since the Llama have size limit of tokens a subset of the post is used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd = cwd.replace('/notebooks', '')\n",
    "directory = os.path.join(cwd, \"tests/data/\")\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    txt_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                txt_files.append(f.read())\n",
    "    return txt_files\n",
    "\n",
    "text_files = read_txt_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 5 seconds</h3>\n",
       "    <textarea cols='100' rows=24.2>and 'The Irishman'\n",
       "- Richard Romanus, actor in Mean Streets, dies at 80\n",
       "- Known for his role as Michael Longo, a loan shark in Little Italy\n",
       "- Handled prominent voice roles for Ralph Bakshi in Wizards and Hey Good Lookin'\n",
       "- Appeared on four episodes of The Sopranos as Richard LaPenna\n",
       "- Son of a dentist, born in Barre, Vermont, and raised in West Hartford, Connecticut\n",
       "- Graduated from Xavier University in Cincinnati in 1964 with a degree in philosophy\n",
       "- Spent a year in law school before studying acting with Lee Strasberg at Carnegie Hall\n",
       "- Appeared on episodes of Mission: Impossible and The Mod Squad and in the David Janssen-starring telefilm Night Chase before he was hired on Mean Streets\n",
       "- Spent the rest of the decade showing up on such shows as Rhoda, Kojak, Starsky & Hutch, The Rockford Files and Hawaii Five-O and in the film Russian Roulette (1975)\n",
       "- Played another cop on another short-lived ABC series, Foul Play, in 1981\n",
       "- Survivors include his second wife, Oscar-nominated costume designer Anthea Sylbert, whom he married in August 1985, and younger brother Robert Romanus, who played Mike Damone in Fast Times at Ridgemont High\n",
       "- Moved to the Greek town of Skiathos in 1998 and wrote about the experience in Act III: A Small Island in the Aegean, published in 2011\n",
       "- Authored two novels set in the country, 2011's Chrysalis and 2014's Matoula's Echo\n",
       "- First wife was actress-singer Tina Bohlmann. They were married from 1967 until their 1975 divorce.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 =  \"\"\"Write a concise summary of the main ideas in article below in bullet-points, don't repeat ideas. article: {BODY}\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 2 seconds</h3>\n",
       "    <textarea cols='100' rows=5.2>{'category': 'news', 'explanation': 'This is a news article about the death of Richard Romanus, an actor known for his role in Mean Streets. The article includes information about his life, career, and family. It also includes quotes from people who knew him and a description of his iconic scene in Mean Streets.'}</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p2 =  \"\"\"How would you categorized the following text? Is it news article, blog, research paper? \n",
    "Answer JSON following this format: {{'category': 'news', 'explanation': 'text of the article'}}.\n",
    "Text: {BODY}\n",
    "JSON:\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=2.9>\n",
       "- Soft launch is a strategy where a game is released to a limited number of players before it is released worldwide, usually by releasing only to specific countries</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p3 =  \"\"\"Summarizes the article in multiple bullet-points. The number of bullet points must below six. article: {BODY}\"\"\".format(BODY=text)\n",
    "p3_answer = run_prompt(p3)\n",
    "display_answer(p3_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bed, Llama listen to me :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirement 2: System Message\n",
    "\n",
    "The Llama paper describe the system message that uses to set the stage and concext for the model. \n",
    "In the following example, I am using the system messsage. Let see what is the different between P3 that doesn't have system message and P4 that use system message.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Internal Server Error\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m p4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m<s>[INST] <<SYS>>\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  \u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mYour answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124marticle: \u001b[39m\u001b[38;5;132;01m{BODY}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(BODY\u001b[38;5;241m=\u001b[39mtext)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# p4_answer = run_prompt(p4)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# display_answer(p4_answer, \"P4 - With System Message\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Display p3 too for comparision. \u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m display_answer(\u001b[43mrun_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp4\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36mrun_prompt\u001b[0;34m(prompt, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m res \u001b[38;5;241m=\u001b[39m together_generate(prompt)\n\u001b[0;32m----> 5\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m elapse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(end_time \u001b[38;5;241m-\u001b[39m start_time)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "p4 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  \n",
    "Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "Write a concise TL;DR summary in numeric bullet-points for the following article. Only include bullet-points. \n",
    "Limit the number of bullet-point to five. Output the answer in JSON format [{{\"1\", bullet-point}}, {{\"2\", bullet-point}}, ...]\n",
    "\n",
    "article: {BODY}\"\"\".format(BODY=text)\n",
    "\n",
    "# p4_answer = run_prompt(p4)\n",
    "# display_answer(p4_answer, \"P4 - With System Message\")\n",
    "# Display p3 too for comparision. \n",
    "\n",
    "display_answer(run_prompt(p4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both P3 and P4 are pretty good and it's hard to see the different the the system message added. I personally prefer P4 (system message) because the answer read a better in my opinion, but I am sure someone will argue with on that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirence 3: Modify the System Message\n",
    "The system message can be modified to better fit to the task and define the persona and context we want Llama to assume. \n",
    "\n",
    "Changes applied to the original system message:\n",
    "- Use the researcher persona and specify the tasks to summarizing articles. \n",
    "- Remove safety instruction, there are not needed since we asking Llama to be truthful to the article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 3 seconds</h3>\n",
       "    <textarea cols='100' rows=3.7>A soft launch in mobile gaming allows developers to test a game in a real-world environment, on a limited scale, before a global release, helping to improve the game and increase the chances of success at launch.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p5 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task in summarizing and writing concise brief of articles.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "In one sentence, tell me what is the main idea of the following article. Limit the answer to tweenty words. \n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer for p5 is the best in my opinion so far. I like the into and conclusion that Llama addeed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirement 4: Asking Questions about the Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article is about 'Mobile Game Soft Launch' let ask Llama specific question about it. The answer is pretty good. \n",
    "\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 4 seconds</h3>\n",
       "    <textarea cols='100' rows=28.6>\n",
       "According to the article \"Play to Win: Mobile Game Soft Launch Best Practices\" by Doug McCracken and Joshua Lu, a soft launch of a mobile game can solve several problems for game studios. A soft launch is the release of a game to a limited number of players before it is released worldwide, usually by releasing only to specific countries. This allows developers to test different aspects of the game, such as the gameplay, graphics, and economy in a real-world environment without the pressure of a full release.\n",
       "\n",
       "One of the main benefits of a soft launch is that it enables player feedback and metrics which can be used to compare to benchmarks offered by Apple’s iOS App Store and Google Play. This can help developers to improve the game before it is released to everyone, and increase the chances of success when the game is launched globally.\n",
       "\n",
       "Additionally, a soft launch can help to dispel some common myths about the process. For example, the country or market chosen for the soft launch may not accurately represent how the game will perform worldwide, and soft launches can also be applied to PC and console games. Furthermore, the investment required for a soft launch is dependent on the goals of the soft launch, and it is not necessary to soft launch a game for it to succeed.\n",
       "\n",
       "A soft launch can also help developers to answer important questions about the game, such as whether it is stable and performant. By acquiring users at scale from lower-cost geographies, developers can stress test servers and get performance data from long-tail devices. This can help to identify and fix any bugs or performance issues before the game is released to a wider audience.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p6 = \"\"\"[INST]\n",
    "You are a researcher task with extracting information from articles.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "According to the article mobile game soft launch solves what problems? Please include examples from the article in your answer. \n",
    "Answer should include at leat 50 words.\n",
    "Article: {BODY}\n",
    "[/INST]\n",
    "Answer:\n",
    "\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good, let see if we improve on that. By asking Llama what is the article is about and then use the answer to ask additional questions. \n",
    "Prompt 7, asks Llama to tell what the article is about and then the answer is used to generate a prompt 8 that ask a second question.\n",
    "\n",
    "To make it easy to programmatically use the answer, I asked Llama to output the answer in JSON. Using expirements (that I didn't included here) I descover that Llama need a template and being told to only output valid JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Answer:\n",
      " {'article_is_about': 'mobile game soft launch best practices'}\n",
      "mobile game soft launch best practices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Prompt 8 Answer - Time to Generate: 2 seconds</h3>\n",
       "    <textarea cols='100' rows=11.2>The article discusses how soft launching a mobile game can help solve several problems. It allows developers to test the game's stability, graphics, gameplay, economy, and other aspects in a real-world environment before a global release (Play to Win: Mobile Game Soft Launch Best Practices). By releasing the game in stages, developers can gather player feedback and metrics to compare with benchmarks offered by Apple's iOS App Store and Google Play. This strategy can help improve the game, retain and monetize users, and facilitate organic growth or paid acquisition. Soft launching can also help determine if the game is stable and performant by stress-testing servers and gathering performance data from long-tail devices.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p7 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "Tell me what is the article about in one to three words? \n",
    "Output the answer in JSON in the following format {{\"article_is_about\": answer}}. Only output JSON\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "a7 = run_prompt(p7)\n",
    "json_a7 = json.loads(a7.answer)\n",
    "print(f\"JSON Answer:\\n {json_a7}\")\n",
    "about = json_a7['article_is_about']\n",
    "print(about)\n",
    "\n",
    "\n",
    "p8 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "According to the article, what problems does {{ABOUT}} solves? Give several short examples from the article in your answer. Limit the answer to fifty words.\n",
    "Article: {BODY}\n",
    "Answer:\n",
    "[/INST]\"\"\".format(BODY=text, ABOUT=about)\n",
    "\n",
    "display_answer(run_prompt(p8),'Prompt 8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow this is awesume. We can feed answers into new prompts to refine the information we try to extract. \n",
    "\n",
    "Let try a different question. What industry the article is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=0.9>The article is focus on the mobile game industry.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p9 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "Name the industry the article is focus on? Output only the industry name.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text, ABOUT=about)\n",
    "\n",
    "display_answer(run_prompt(p9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I asked the answer to include only the industry name, but Llama disregarded my request and wrote a sentence. \n",
    "Let see if we can fixed that by asking the answer to be in JSON. It worked!!! \n",
    "\n",
    "Note: I needed to add \"include only valid JSON\" to prevent Llama then adding an explanation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=0.3>{\"industry\": \"Mobile Game\"}</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p10 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "Name industry the article is focus on? Output only the industry name. Output the answer in JSON, using format {{\"industry\": industry}}.\n",
    "Include only valid JSON.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try and trick Llama and ask him what sport is the article focuses on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=2.6>{\"sport\": \"Not applicable\", \"explanation\": \"The article does not focus on a specific sport. It discusses best practices for launching a mobile game, including soft launch strategies.\"}</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p11 = \"\"\"[INST]\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "Name sport the article is focus on? Output only the sport name. Output the answer in JSON, using format {{\"sport\": sport, \"explanation\": explanation}}. \n",
    "Include only valid JSON. Make sure to close the JSON object with a curly bracket.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 4 seconds</h3>\n",
       "    <textarea cols='100' rows=23.1>[\n",
       "{\"name\": \"soft launch\", \"type\": \"mobile game development strategy\", \"explanation\": \"A strategy for releasing a game to a limited number of players before it is released worldwide, usually by releasing only to specific countries. This allows developers to test different aspects of the game, such as the gameplay, graphics, and economy in a real-world environment without the pressure of a full release.\"},\n",
       "{\"name\": \"mobile game\", \"type\": \"type of game\", \"explanation\": \"A game designed to be played on mobile devices like smartphones and tablets.\"},\n",
       "{\"name\": \"game studios\", \"type\": \"company\", \"explanation\": \"Companies that develop and publish video games.\"},\n",
       "{\"name\": \"players\", \"type\": \"game stakeholder\", \"explanation\": \"Individuals who play mobile games.\"},\n",
       "{\"name\": \"Apple App Store\", \"type\": \"mobile app marketplace\", \"explanation\": \"A digital distribution platform for mobile apps on iOS devices.\"},\n",
       "{\"name\": \"Google Play Store\", \"type\": \"mobile app marketplace\", \"explanation\": \"A digital distribution platform for mobile apps on Android devices.\"},\n",
       "{\"name\": \"alpha\", \"type\": \"soft launch stage\", \"explanation\": \"The earlier stage of soft launch, used to test the core of the game, including the technology and core gameplay loop.\"},\n",
       "{\"name\": \"beta\", \"type\": \"soft launch stage\", \"explanation\": \"The later stage of soft launch, used to test the meta gameplay loop, marketing acquisition, server scalability, and monetization.\"},\n",
       "{\"name\": \"retention\", \"type\": \"game metric\", \"explanation\": \"The percentage of players who continue to play a game over a certain period of time.\"},\n",
       "{\"name\": \"monetization\", \"type\": \"game metric\", \"explanation\": \"The process of generating revenue from a game, typically through in-app purchases or advertising.\"}\n",
       "]</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p12 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "Output answer in JSON using the following format: {{\"name\": name, \"type\": type, \"explanation\": explanation}}\n",
    "<</SYS>>\n",
    "\n",
    "What entities mentioned in the article that can generalize the topic? [/INST] \n",
    "[\n",
    "{{\"name\": \"semiconductor\", \"type\": \"industry\", \"explanation\": \"Companies engaged in the design and fabrication of semiconductors and semiconductor devices\"}},\n",
    "{{\"name\": \"NBA\", \"type\": \"sport league\", \"explanation\": \"NBA is the national basketball league\"}},\n",
    "{{\"name\": \"Ford F150\", \"type\": \"vehicle\", \"explanation\": \"Article talks about the Ford F150 truck\"}},\n",
    "] </s>\n",
    "\n",
    "<s>[INST]   \n",
    "What entities mentioned are important to the article subject? Limit the answert to ten most important entities. \n",
    "Output answer in JSON using the following format: {{\"name\": name, \"type\": type, \"explanation\": explanation}}\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m      1\u001b[0m p13 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m<s>[INST] <<SYS>>\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are a researcher task with answering questions about an article.  \u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mPlease ensure that your responses are socially unbiased and positive in nature.\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mIf you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know the answer, please don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt share false information.\u001b[39m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m<</SYS>>\u001b[39m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mAnswers output must confirm to the this JSON format [/INST] \u001b[39m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mJSON Output: \u001b[39m\u001b[38;5;124m{{\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moneSentenceSummary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMobile game soft launch is a process of releasing a game to a limited audience for testing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummaryInNumericBulletPoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : [\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m]\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities : [\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msemiconductor\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindustry\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplanation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompanies engaged in the design and fabrication of semiconductors and semiconductor devices\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}},\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNBA\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msport league\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplanation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNBA is the national basketball league\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}},\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFord F150\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvehicle\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplanation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticle talks about the Ford F150 truck\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}},\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m]\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m}} </s>\u001b[39m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m<s>[INST]\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124mUse the examples above to answer the following question.\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m1. Summarize the article in one sentence. Limit the answer to twenty words.\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m2. Summarize the article in multiple bullet-points. Each bullet-point need to have betweeen ten to tweenty words. Limit the number of bullet points must below six.\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m3. Identify ten entities (companies, people, location, products....) mentioned in the article. Include short explanation for each entity.\u001b[39m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124mUse the JSON format above to output your answer. Only output valid JSON format.\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124mArticle: \u001b[39m\u001b[38;5;132;01m{BODY}\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;124m[/INST]\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(BODY\u001b[38;5;241m=\u001b[39m\u001b[43mtext\u001b[49m)\n\u001b[1;32m     34\u001b[0m display_answer(run_prompt(p13))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "p13 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "Answers output must confirm to the this JSON format [/INST] \n",
    "\n",
    "JSON Output: {{\n",
    "\"oneSentenceSummary\" : \"Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "\"summaryInNumericBulletPoints\" : [\n",
    "\"1. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "\"2. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "]\n",
    "\"entities : [\n",
    "{{\"name\": \"semiconductor\", \"type\": \"industry\", \"explanation\": \"Companies engaged in the design and fabrication of semiconductors and semiconductor devices\"}},\n",
    "{{\"name\": \"NBA\", \"type\": \"sport league\", \"explanation\": \"NBA is the national basketball league\"}},\n",
    "{{\"name\": \"Ford F150\", \"type\": \"vehicle\", \"explanation\": \"Article talks about the Ford F150 truck\"}},\n",
    "]\n",
    "}} </s>\n",
    "\n",
    "<s>[INST]\n",
    "Use the examples above to answer the following question.\n",
    "1. Summarize the article in one sentence. Limit the answer to twenty words.\n",
    "2. Summarize the article in multiple bullet-points. Each bullet-point need to have betweeen ten to tweenty words. Limit the number of bullet points must below six.\n",
    "3. Identify ten entities (companies, people, location, products....) mentioned in the article. Include short explanation for each entity.\n",
    "\n",
    "Use the JSON format above to output your answer. Only output valid JSON format.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"~/Projects/icognition-backend/tests/data/\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    txt_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                txt_files.append(f.read())\n",
    "    return txt_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
